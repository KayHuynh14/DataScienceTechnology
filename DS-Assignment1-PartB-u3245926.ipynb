{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d5fd1c8",
   "metadata": {},
   "source": [
    "# DATA SCIENCE TECHNOLOGY AND SYSTEM\n",
    "# Assignment – 1\n",
    "### Predictive Modelling of Eating-Out problem\n",
    "Student name: Kay Huynh\n",
    "Student ID: u3245926"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c54102",
   "metadata": {},
   "source": [
    "### Part B – Predictive Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c692f",
   "metadata": {},
   "source": [
    "#### I. Feature Engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a30354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff829820",
   "metadata": {},
   "source": [
    "##### 1. Perform data cleaning to remove/impute any records that are useless in the predictive task (such as NA, NaN, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data= pd.read_csv('data\\zomato_df_final_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b314447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting Unnnecessary Columns\n",
    "data=data.drop(['link','color','phone','cuisine_color','address','lat','lng'],axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuisine column processing \n",
    "data['cuisine'] = data['cuisine'].str.split(', ')\n",
    "restaurant_df = data.explode(\"cuisine\").reset_index(drop=True)\n",
    "restaurant_df['cuisine'] = restaurant_df['cuisine'].astype(str)\n",
    "restaurant_df['cuisine'] = restaurant_df['cuisine'].str.replace('[', '')\n",
    "restaurant_df['cuisine'] = restaurant_df['cuisine'].str.replace(\"'\", '')\n",
    "restaurant_df['cuisine'] = restaurant_df['cuisine'].str.replace(\"]\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e644dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type column processing \n",
    "restaurant_df['type'] = restaurant_df ['type'].str.split(', ')\n",
    "restaurant_df = restaurant_df.explode(\"type\").reset_index(drop=True)\n",
    "restaurant_df['type'] = restaurant_df['type'].astype(str)\n",
    "restaurant_df['type'] = restaurant_df['type'].str.replace('[', '')\n",
    "restaurant_df['type'] = restaurant_df['type'].str.replace(\"'\", '')\n",
    "restaurant_df['type'] = restaurant_df['type'].str.replace(\"]\", '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52664dbf",
   "metadata": {},
   "source": [
    "##### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7acf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data shape\n",
    "print(restaurant_df.shape)\n",
    "# column names\n",
    "print(restaurant_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bbc538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of dataset\n",
    "print(restaurant_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f644b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of missing value in dataset\n",
    "count_missing_df = restaurant_df.isna().sum()\n",
    "count_missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0e8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the target variable has any na/null values\n",
    "restaurant_df = restaurant_df[restaurant_df['rating_number'].notna()]\n",
    "print(restaurant_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f819c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore categorical variables\n",
    "# types of variables\n",
    "# categrical variables\n",
    "categorical = [var for var in restaurant_df.columns if restaurant_df[var].dtype=='O']\n",
    "print(\"There are {} categorical variables\\n\".format(len(categorical)))\n",
    "print(\"The categorical variables are: \", categorical)\n",
    "restaurant_df[categorical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd866ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frequency counts of the categorical variables\n",
    "for var in categorical:\n",
    "    print(restaurant_df[var].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695b5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentages in each of the categorical variables\n",
    "for var in categorical:\n",
    "    print(restaurant_df[var].value_counts() / restaurant_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd6216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to explore each of the categorical variables\n",
    "def explore_categorical(df, var):\n",
    "    # check if the variable has any missing values\n",
    "    print('********** missing values **********')\n",
    "    print(df[var].isnull().sum())\n",
    "    print('********** Labels **********')\n",
    "    # check unique lables in variable\n",
    "    print(df[var].unique())\n",
    "    print('********** frequency **********')\n",
    "    # check frequency of each variable\n",
    "    print(df[var].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_categorical(restaurant_df, 'cuisine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_categorical(restaurant_df, 'rating_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c3758",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_categorical(restaurant_df, 'subzone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae02a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_categorical(restaurant_df, 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfa7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_categorical(restaurant_df, 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9149a7",
   "metadata": {},
   "source": [
    "##### Explore Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca58636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find numerical variables\n",
    "numericals = [var for var in restaurant_df.columns if restaurant_df[var].dtype != 'O']\n",
    "print('There are {} numerical variables\\n'.format(len(numericals)))\n",
    "print('The numerical variables are :', numericals)\n",
    "restaurant_df[numericals].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a67432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore problems within numerical variables\n",
    "# Check missing values in numerical variables\n",
    "restaurant_df[numericals].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c3247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view summary statistics in numerical variables\n",
    "print(round(restaurant_df[numericals].describe()), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's draw boxplots to visualise outliers in these variables\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(2,2,1)\n",
    "fig = restaurant_df.boxplot(column= 'cost')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('Cost')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "fig = restaurant_df.boxplot(column= 'rating_number')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('Rating')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "fig = restaurant_df.boxplot(column= 'votes')\n",
    "fig.set_title('')\n",
    "fig.set_ylabel('Votes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ce524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram to check distribution\n",
    "y = restaurant_df['rating_number']\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "fig = restaurant_df['cost'].hist(bins=50)\n",
    "fig.set_xlabel('Cost')\n",
    "fig.set_ylabel('Rating')\n",
    "\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "fig = restaurant_df[\"votes\"].hist(bins=50)\n",
    "fig.set_xlabel('Votes')\n",
    "fig.set_ylabel('Rating')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a34c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find aoutliers in these variables\n",
    "def find_outliers(variable, factor= 3, print_summary=True):\n",
    "    IQR = restaurant_df[variable].quantile(0.75) - restaurant_df[variable].quantile(0.25)\n",
    "    Lower_boundary = restaurant_df[variable].quantile(0.25) - (IQR * factor)\n",
    "    Upper_boundary = restaurant_df[variable].quantile(0.75) + (IQR * factor)\n",
    "    \n",
    "    outliers= []\n",
    "    for index, val in enumerate(restaurant_df[variable]):\n",
    "        if val < Lower_boundary or val > Upper_boundary:\n",
    "            outliers.append(index)\n",
    "    \n",
    "    \n",
    "    if(print_summary):\n",
    "        print('{variable} outliers are values < {lowerboundary} or > {upperboundary}'.format(variable= variable, lowerboundary=Lower_boundary, upperboundary=Upper_boundary))\n",
    "    return Lower_boundary, Upper_boundary, outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_,_,_ = find_outliers('cost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d563a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_,_,_ = find_outliers('rating_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e77d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_,_,_ = find_outliers('votes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486bef8c",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec31bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafdbfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display categorical variables\n",
    "categorical = [var for var in restaurant_df.columns if restaurant_df[var].dtypes == 'O']\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01475ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display numerical variables\n",
    "numericals = [var for var in restaurant_df.columns if restaurant_df[var].dtypes != 'O']\n",
    "numericals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd6d19",
   "metadata": {},
   "source": [
    "#### Engineering missing values in numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1964193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display missing values\n",
    "restaurant_df[numericals].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc59e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of missing values in each variable\n",
    "round(restaurant_df[numericals].isnull().mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values with the median values -- median is robust with the outliers\n",
    "for df_temp in [restaurant_df]:\n",
    "    for col in numericals:\n",
    "        col_median = restaurant_df[col].median() # get it only from training\n",
    "        df_temp[col].fillna(col_median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a37110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again missing values in numerical variables in X_train\n",
    "restaurant_df[numericals].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef369b79",
   "metadata": {},
   "source": [
    "#### Engineering missing values in categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ebb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(restaurant_df[categorical].isnull().mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bb23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing categorical variables with most frequent value (i.e., mode)\n",
    "for df_temp in [restaurant_df]:\n",
    "    for col in categorical:\n",
    "        col_mode = restaurant_df[col].mode()[0] # get it only from training\n",
    "        df_temp[col].fillna(col_mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7337dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values in categorical variables in data\n",
    "restaurant_df[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2a514",
   "metadata": {},
   "source": [
    "#### Engineering outliers in numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4015353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the outliers with some predefined the maximum value for each variable\n",
    "def max_value(df_temp, variable, top):\n",
    "    return np.where(df_temp[variable]>top, top, df_temp[variable])\n",
    "\n",
    "cols_with_outliers = {'cost': 160, \n",
    "                      'votes': 377\n",
    "                     }\n",
    "for df_temp in [restaurant_df]:\n",
    "    for col in cols_with_outliers:\n",
    "        df_temp[col] = max_value(df_temp, col, cols_with_outliers[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98693b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df.cost.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3dff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df.votes.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aed4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use seaborn library to plot elegant ones\n",
    "df_custom = restaurant_df[['cost', 'votes']]\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = sns.boxplot(data=df_custom, orient=\"h\", palette=\"Set2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981f291c",
   "metadata": {},
   "source": [
    "##### 2. Use proper label/feature encoding for each feature/column you consider making the data ready for the modelling step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610ba36",
   "metadata": {},
   "source": [
    "#### Encoding the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05850369",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df[categorical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the input Variables\n",
    "def Encode(restaurant_df):\n",
    "    for column in restaurant_df.columns[~restaurant_df.columns.isin(['cost', 'votes'])]:\n",
    "        restaurant_df[column] = restaurant_df[column].factorize()[0]\n",
    "    return restaurant_df\n",
    "\n",
    "df_en = Encode(restaurant_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7527b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da8c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Correlation between different variables\n",
    "corr = df_en.corr(method='kendall')\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(corr, annot=True)\n",
    "df_en.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d99c10",
   "metadata": {},
   "source": [
    "#### II. Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd37368",
   "metadata": {},
   "source": [
    "##### 3. Build a linear regression model (model_regression_1) to predict the restaurants rating (numeric rating) from other features (columns) in the dataset. Please consider splitting the data into train (80%) and test (20%) sets.\n",
    "[Hint: please use sklearn.model_selection.train_test_split and set random_state=0 “\n",
    "while splitting]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce7fac",
   "metadata": {},
   "source": [
    "##### Declare source and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_en.drop(['rating_number'], axis=1)\n",
    "y = df_en['rating_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c9b4e",
   "metadata": {},
   "source": [
    "#### Split data into separate training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40fdb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d163218a",
   "metadata": {},
   "source": [
    "##### Model training using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71902b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model\n",
    "model_LR = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "model_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f6bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict results\n",
    "y_pred_LR = model_LR.predict(X_test)\n",
    "\n",
    "y_pred_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_LR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f72080",
   "metadata": {},
   "source": [
    "##### 4. Build another linear regression model (model_regression_2) with using the Gradient Descent as the optimisation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be51bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for inear regression model  Gradient Descent as the optimisation function\n",
    "# X = df_en.drop([['rating_number','cuisine','groupon', 'cost_2',\"title\", 'rating_text','votes','cost','subzone']].value()\n",
    "X = df_en[['rating_text','votes','cost','subzone','type']].values\n",
    "y = df_en['rating_number'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64694375",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "X_train_GD, X_test_GD, y_train_GD, y_test_GD = train_test_split(X, y, test_size = test_size, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7949988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of ones to the feature matrix for the bias term\n",
    "X_train_GD_b = np.c_[np.ones((X_train_GD.shape[0], 1)), X_train_GD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionGD:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Initialize weights\n",
    "        self.weights = np.random.randn(X.shape[1])\n",
    "\n",
    "        # Perform gradient descent\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Compute predictions\n",
    "            predictions = np.dot(X, self.weights)\n",
    "\n",
    "            # Compute errors\n",
    "            errors = predictions - y\n",
    "\n",
    "            # Update weights using gradients\n",
    "            gradient_weights = (1 / len(X)) * np.dot(X.T, errors)\n",
    "\n",
    "            self.weights -= self.learning_rate * gradient_weights\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ecfe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LinearRegressionGD instance\n",
    "model = LinearRegressionGD(learning_rate=0.01, n_iterations=1000)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_GD_b, y_train_GD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test data\n",
    "X_test_GD_b = np.c_[np.ones((X_test.shape[0], 1)), X_test_GD]\n",
    "y_pred_GDLR = model.predict(X_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7affb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_GDLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db40863",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_GD_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46288e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_GD_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c657117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_GDLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0acf61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results (for a single feature)\n",
    "plt.scatter(X_test_GD[:, 0], y_test_GD, label=\"Original Data\")  # Replace 0 with the appropriate feature index\n",
    "plt.plot(X_test_GD[:, 0], y_pred_GDLR, 'r-', label=\"Regression Line\", linewidth=2)  # Replace 0 with the same feature index\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aae9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results (for a single feature)\n",
    "plt.scatter(X_test_GD[:, 1], y_test_GD, label=\"Original Data\")  # Replace 0 with the appropriate feature index\n",
    "plt.plot(X_test_GD[:, 1], y_pred_GDLR, 'r-', label=\"Regression Line\", linewidth=2)  # Replace 0 with the same feature index\n",
    "plt.xlabel(\"Feature 2\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ff948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results (for a single feature)\n",
    "plt.scatter(X_test_GD[:, 2], y_test_GD, label=\"Original Data\")  # Replace 0 with the appropriate feature index\n",
    "plt.plot(X_test_GD[:, 2], y_pred_GDLR, 'r-', label=\"Regression Line\", linewidth=2)  # Replace 0 with the same feature index\n",
    "plt.xlabel(\"Feature 3\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b07089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results (for a single feature)\n",
    "plt.scatter(X_test_GD[:, 3], y_test_GD, label=\"Original Data\")  # Replace 0 with the appropriate feature index\n",
    "plt.plot(X_test_GD[:, 3], y_pred_GDLR, 'r-', label=\"Regression Line\", linewidth=2)  # Replace 0 with the same feature index\n",
    "plt.xlabel(\"Feature 4\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ea106",
   "metadata": {},
   "source": [
    "##### 5. Report the mean square error (MSE) on the test data for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Calculate the Mean Squared Error (MSE) between predicted and actual values for Regression model\n",
    "mse_LR = mean_squared_error(y_test, y_pred_LR)\n",
    "mse_LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977cfe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_GDLR = mean_squared_error(y_test_GD, y_pred_GDLR)\n",
    "mse_GDLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465e611e",
   "metadata": {},
   "source": [
    "#### III. Classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b25da5",
   "metadata": {},
   "source": [
    "##### 6. Simplify the problem into binary classifications where class 1 contains ‘Poor’ and ‘Average’ records while class 2 contains ‘Good’, ‘Very Good’ and ‘Excellent’ records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062eb0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping for the ratings\n",
    "rating_mapping = {\n",
    "    'Poor': 1,\n",
    "    'Average': 1,\n",
    "    'Good': 2,\n",
    "    'Very Good': 2,\n",
    "    'Excellent': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'binary_rating' based on the mapping\n",
    "restaurant_df['binary_rating'] = restaurant_df['rating_text'].map(rating_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a0a29",
   "metadata": {},
   "source": [
    "##### 7. Build a logistic regression model (model_classification_3) for the simplified data, where training data is 80% and the test data is 20%.\n",
    "[Hint: please use sklearn.model_selection.train_test_split and set random_state=0 “\n",
    "while splitting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c6f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the input Variables\n",
    "def Encode(restaurant_df):\n",
    "    for column in restaurant_df.columns[~restaurant_df.columns.isin(['cost', 'votes'])]:\n",
    "        restaurant_df[column] = restaurant_df[column].factorize()[0]\n",
    "    return restaurant_df\n",
    "\n",
    "df_en = Encode(restaurant_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_en.drop(['binary_rating'], axis=1)\n",
    "y = df_en['binary_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361f4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b827a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "model_classification_3 = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "model_classification_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366a53d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_3 = model_classification_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eca72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy = accuracy_score(y_test, y_pred_3)\n",
    "classification_rep = classification_report(y_test, y_pred_3)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5721dee",
   "metadata": {},
   "source": [
    "##### 8. Use the confusion matrix to report the results of using the classification model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_3)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d182d",
   "metadata": {},
   "source": [
    "##### 9. Draw your conclusions and observations about the performance of the model relevant to the classes’ distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_normalised = cm.astype('float32') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# visualize confusion matrix with seaborn heatmap\n",
    "cm_matrix = pd.DataFrame(data=cm_normalised, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='.2f', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879d1dc",
   "metadata": {},
   "source": [
    "##### Bonus: Repeat the previous classification task using three other models of your choice and report the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8844a7b4",
   "metadata": {},
   "source": [
    "##### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c472685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Regression model\n",
    "# Import package\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Build model\n",
    "model_DecisionTree = DecisionTreeRegressor(min_samples_leaf=.0001)\n",
    "\n",
    "# Fit model on train data\n",
    "model_DecisionTree.fit(X_train,y_train)\n",
    "\n",
    "# Predict test data\n",
    "y_pred_DT = model_DecisionTree.predict(X_test)\n",
    "\n",
    "# Print accuracy score\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_DT)))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a27a940",
   "metadata": {},
   "source": [
    "##### Gaussian Naive Bayes (GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5872175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Build model\n",
    "model_GNB = GaussianNB()\n",
    "\n",
    "# Fit model on train data\n",
    "model_GNB.fit(X_train, y_train)\n",
    "\n",
    "# Predict test data\n",
    "y_pred_GNB = model_GNB.predict(X_test)\n",
    "\n",
    "# Print accuracy score\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_GNB)))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_GNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cde7d1",
   "metadata": {},
   "source": [
    "##### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ec6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Build model\n",
    "model_MLP = MLPClassifier(random_state=1, max_iter=500)\n",
    "\n",
    "# Fit model on train data\n",
    "model_MLP.fit(X_train, y_train)\n",
    "\n",
    "# Predict test data\n",
    "y_pred_MLP = model_MLP.predict(X_test)\n",
    "\n",
    "# Print accuracy score\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_MLP)))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_MLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402e6d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Save trained model\n",
    "joblib.dump(model_LR, 'model_LR.pkl')\n",
    "# joblib.dump(model_GDLR, 'model_GDLR.pkl')\n",
    "joblib.dump(model_DecisionTree, 'model_DecisionTree.pkl')\n",
    "joblib.dump(model_GNB, 'model_GNB.pkl')\n",
    "joblib.dump(model_MLP, 'model_MLP.pkl')\n",
    "joblib.dump(model_classification_3, 'model_classification_3.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
